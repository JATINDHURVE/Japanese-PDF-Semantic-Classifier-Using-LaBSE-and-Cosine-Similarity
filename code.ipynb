{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cd2663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JatinDhurve(VBAFMCwo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aabcacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8208427a",
   "metadata": {},
   "source": [
    "## Creating vectors for ESRS TOPICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deec77af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Japanese topics\n",
    "topics = [\n",
    "    \"気候変動\", \"気候変動への適応\", \"気候変動の緩和\", \"エネルギー\",\n",
    "    \"空気の汚染\", \"水の汚染\", \"土壌汚染\", \"生物および食料資源の汚染\",\n",
    "    \"懸念物質\", \"非常に懸念の高い物質\", \"マイクロプラスチック\",\n",
    "    \"水の消費と取水\", \"放水\", \"海洋資源の使用\", \"海洋資源の採取と利用\",\n",
    "    \"生物多様性の損失\", \"侵略的外来種\", \"種の個体数\", \"絶滅リスク\", \"砂漠化\",\n",
    "    \"循環経済\", \"無駄\", \"労働条件\", \"適切な賃金\", \"労働時間\", \"健康と安全\",\n",
    "    \"平等と機会\", \"障害者の雇用\", \"児童労働\", \"プライバシー\", \"文化的権利\",\n",
    "    \"企業文化\", \"ロビー活動\", \"贈収賄\", \"動物福祉\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42036958",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09574128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Encode topic phrases using the same model (LaBSE)\n",
    "topic_embeddings = model.encode(topics, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# Step 3: Store in a new DataFrame\n",
    "topic_df = pd.DataFrame({\n",
    "    'topic': topics,\n",
    "    'embedding_topic': topic_embeddings.tolist()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c0e0281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>embedding_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>気候変動</td>\n",
       "      <td>[-0.03803761675953865, -0.04873177781701088, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>気候変動への適応</td>\n",
       "      <td>[-0.00950303953140974, -0.040512144565582275, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>気候変動の緩和</td>\n",
       "      <td>[-0.03168332204222679, -0.022349612787365913, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>エネルギー</td>\n",
       "      <td>[0.01078301016241312, -0.05533900484442711, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>空気の汚染</td>\n",
       "      <td>[-0.06226995214819908, -0.034258317202329636, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                    embedding_topic\n",
       "0      気候変動  [-0.03803761675953865, -0.04873177781701088, -...\n",
       "1  気候変動への適応  [-0.00950303953140974, -0.040512144565582275, ...\n",
       "2   気候変動の緩和  [-0.03168332204222679, -0.022349612787365913, ...\n",
       "3     エネルギー  [0.01078301016241312, -0.05533900484442711, -0...\n",
       "4     空気の汚染  [-0.06226995214819908, -0.034258317202329636, ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Check result\n",
    "topic_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6871ce",
   "metadata": {},
   "source": [
    "## EXTRACTING TEXT FROM THE PDF FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cce080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder = \"JAPANESE_FILES\" \n",
    "output_folder = \"sentence_embdedding_files\"  \n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35b77674",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/LaBSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8261797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_japanese_sentences(text):\n",
    "    sentences = re.split(r'(?<=[。！？])', text)\n",
    "    cleaned = []\n",
    "    for s in sentences:\n",
    "        s = s.strip()\n",
    "        if len(s) > 10 and not re.match(r'^[\\d\\W_]+$', s):\n",
    "            cleaned.append(s)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb13da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_sentence(sentence):\n",
    "    if re.search(r'https?://', sentence):\n",
    "        return False\n",
    "    if len(re.findall(r'[一-龯ぁ-ゔァ-ヴー々〆〤]', sentence)) < 5:\n",
    "        return False\n",
    "    if re.match(r'^[\\d\\W_]+$', sentence):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f310dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_is_valid_sentence(sentence):\n",
    "    if re.search(r'https?://', sentence):\n",
    "        return False\n",
    "    if len(re.findall(r'[一-龯ぁ-ゔァ-ヴー々〆〤]', sentence)) < 6:\n",
    "        return False\n",
    "    if len(sentence) < 15:\n",
    "        return False\n",
    "    if re.match(r'^[\\d\\W\\s_]+$', sentence):\n",
    "        return False\n",
    "    if sentence.count('\\n') > 1 or len(sentence.split()) < 3:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbcfd851",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_files = []  # List of (filename, sentence_count)\n",
    "skipped_files = []    # List of (filename, reason)\n",
    "failed_files = []     # List of (filename, error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "178aea96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 01_JAPAN_TABACCO.pdf\n",
      "✅ Saved: sentence_embdedding_files\\01_JAPAN_TABACCO.csv\n",
      "Processing: 02_SEVEN&AI_HD.pdf\n",
      "✅ Saved: sentence_embdedding_files\\02_SEVEN&AI_HD.csv\n",
      "Processing: 03_SHINETSU_CHEMISTRY.pdf\n",
      "✅ Saved: sentence_embdedding_files\\03_SHINETSU_CHEMISTRY.csv\n",
      "Processing: 04_TAKEDA_PHARMA.pdf\n",
      "✅ Saved: sentence_embdedding_files\\04_TAKEDA_PHARMA.csv\n",
      "Processing: 05_CHUGAI_PHARMA.pdf\n",
      "✅ Saved: sentence_embdedding_files\\05_CHUGAI_PHARMA.csv\n",
      "Processing: 06_TERUMO.pdf\n",
      "✅ Saved: sentence_embdedding_files\\06_TERUMO.csv\n",
      "Processing: 07_DAIICHI_SANKYO_PHARMA.pdf\n",
      "✅ Saved: sentence_embdedding_files\\07_DAIICHI_SANKYO_PHARMA.csv\n",
      "Processing: 08_ORIENTAL_LAND.pdf\n",
      "✅ Saved: sentence_embdedding_files\\08_ORIENTAL_LAND.csv\n",
      "Processing: 09_FUJIFILM_HD.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\09_FUJIFILM_HD.csv\n",
      "Processing: 10_BRIDGESTONE.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\10_BRIDGESTONE.csv\n",
      "Processing: 11_NIPPONSTEEL.pdf\n",
      "✅ Saved: sentence_embdedding_files\\11_NIPPONSTEEL.csv\n",
      "Processing: 12_RECRUIT_HD.pdf\n",
      "✅ Saved: sentence_embdedding_files\\12_RECRUIT_HD.csv\n",
      "Processing: 14_NIPPON_YUBIN.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\14_NIPPON_YUBIN.csv\n",
      "Processing: 15_TOYOTA_INDUSTRIES_CORP.pdf\n",
      "✅ Saved: sentence_embdedding_files\\15_TOYOTA_INDUSTRIES_CORP.csv\n",
      "Processing: 16_SMC_CORP.pdf\n",
      "⚠️ Skipping 16_SMC_CORP.pdf — No valid sentences after filtering.\n",
      "Processing: 17_KOMATSU.pdf\n",
      "✅ Saved: sentence_embdedding_files\\17_KOMATSU.csv\n",
      "Processing: 18_DAIKIN.pdf\n",
      "✅ Saved: sentence_embdedding_files\\18_DAIKIN.csv\n",
      "Processing: 19_HITACHI.pdf\n",
      "✅ Saved: sentence_embdedding_files\\19_HITACHI.csv\n",
      "Processing: 20_MITSAUBISHI_ELECTRIC.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\20_MITSAUBISHI_ELECTRIC.csv\n",
      "Processing: 21_NIDEC.pdf\n",
      "✅ Saved: sentence_embdedding_files\\21_NIDEC.csv\n",
      "Processing: 22_FUJITSU.pdf\n",
      "✅ Saved: sentence_embdedding_files\\22_FUJITSU.csv\n",
      "Processing: 23_RENESUS.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\23_RENESUS.csv\n",
      "Processing: 24_PANASONIC_HD.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\24_PANASONIC_HD.csv\n",
      "Processing: 25_SONY.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\25_SONY.csv\n",
      "Processing: 26_ADVANTEST.pdf\n",
      "✅ Saved: sentence_embdedding_files\\26_ADVANTEST.csv\n",
      "Processing: 27_KEYENCE.pdf\n",
      "⚠️ Skipping 27_KEYENCE.pdf — No valid sentences after filtering.\n",
      "Processing: 28_DENSO.pdf\n",
      "✅ Saved: sentence_embdedding_files\\28_DENSO.csv\n",
      "Processing: 30_FANUC.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\30_FANUC.csv\n",
      "Processing: 31_KYOCERA.pdf\n",
      "✅ Saved: sentence_embdedding_files\\31_KYOCERA.csv\n",
      "Processing: 32_MURATA.pdf\n",
      "✅ Saved: sentence_embdedding_files\\32_MURATA.csv\n",
      "Processing: 33_MITSUBISHI_HEAVY_INDUSTRIES.pdf\n",
      "✅ Saved: sentence_embdedding_files\\33_MITSUBISHI_HEAVY_INDUSTRIES.csv\n",
      "Processing: 34_YUCHO_BANK.pdf\n",
      "✅ Saved: sentence_embdedding_files\\34_YUCHO_BANK.csv\n",
      "Processing: 35_TOYOTA_MOTOR_CORP.pdf\n",
      "✅ Saved: sentence_embdedding_files\\35_TOYOTA_MOTOR_CORP.csv\n",
      "Processing: 36_HONDA.pdf\n",
      "✅ Saved: sentence_embdedding_files\\36_HONDA.csv\n",
      "Processing: 37_SUZUKI.pdf\n",
      "✅ Saved: sentence_embdedding_files\\37_SUZUKI.csv\n",
      "Processing: 38_HOYA.pdf\n",
      "✅ Saved: sentence_embdedding_files\\38_HOYA.csv\n",
      "Processing: 39_CANON.pdf\n",
      "✅ Saved: sentence_embdedding_files\\39_CANON.csv\n",
      "Processing: 40_NINTENDO.pdf\n",
      "⚠️ Skipping 40_NINTENDO.pdf — No valid sentences after filtering.\n",
      "Processing: 41_ITOCHU.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\41_ITOCHU.csv\n",
      "Processing: 42_MARUBENI.pdf\n",
      "✅ Saved: sentence_embdedding_files\\42_MARUBENI.csv\n",
      "Processing: 43_TOYOTA_TSUSHO.pdf\n",
      "✅ Saved: sentence_embdedding_files\\43_TOYOTA_TSUSHO.csv\n",
      "Processing: 44_MITSUI_CORP.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\44_MITSUI_CORP.csv\n",
      "Processing: 45_TOKYO_ELECTRON.pdf\n",
      "✅ Saved: sentence_embdedding_files\\45_TOKYO_ELECTRON.csv\n",
      "Processing: 46_SUMITOMO_CORP.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\46_SUMITOMO_CORP.csv\n",
      "Processing: 47_MITSUBISHI_CORP.pdf\n",
      "✅ Saved: sentence_embdedding_files\\47_MITSUBISHI_CORP.csv\n",
      "Processing: 48_UNICHARM.pdf\n",
      "✅ Saved: sentence_embdedding_files\\48_UNICHARM.csv\n",
      "Processing: 49_AEON.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\49_AEON.csv\n",
      "Processing: 50_MUFG.pdf\n",
      "✅ Saved: sentence_embdedding_files\\50_MUFG.csv\n",
      "Processing: 52_MIZUHO.pdf\n",
      "✅ Saved: sentence_embdedding_files\\52_MIZUHO.csv\n",
      "Processing: 53_ORIX.pdf\n",
      "✅ Saved: sentence_embdedding_files\\53_ORIX.csv\n",
      "Processing: 54_NOMURA_SEC_HD.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\54_NOMURA_SEC_HD.csv\n",
      "Processing: 55_SOMPO_HD.pdf\n",
      "✅ Saved: sentence_embdedding_files\\55_SOMPO_HD.csv\n",
      "Processing: 56_MS&AD_INSURE_G.pdf\n",
      "✅ Saved: sentence_embdedding_files\\56_MS&AD_INSURE_G.csv\n",
      "Processing: 57_DAIICHI_LIFE.pdf\n",
      "✅ Saved: sentence_embdedding_files\\57_DAIICHI_LIFE.csv\n",
      "Processing: 58_TOKIO_MARINE.pdf\n",
      "✅ Saved: sentence_embdedding_files\\58_TOKIO_MARINE.csv\n",
      "Processing: 59_MITSU_FUDOSAN.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\59_MITSU_FUDOSAN.csv\n",
      "Processing: 60_MITSUBISHI_ESTATE.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: sentence_embdedding_files\\60_MITSUBISHI_ESTATE.csv\n",
      "Processing: 61_JR_EAST.pdf\n",
      "✅ Saved: sentence_embdedding_files\\61_JR_EAST.csv\n",
      "Processing: 62_JR_TOKAI.pdf\n",
      "⚠️ Skipping 62_JR_TOKAI.pdf — No extractable text.\n",
      "Processing: 63_NTT.pdf\n",
      "✅ Saved: sentence_embdedding_files\\63_NTT.csv\n",
      "Processing: 64_KDDI.pdf\n",
      "✅ Saved: sentence_embdedding_files\\64_KDDI.csv\n",
      "Processing: 65_SOFTBANK.pdf\n",
      "✅ Saved: sentence_embdedding_files\\65_SOFTBANK.csv\n",
      "Processing: 66_NTT_DATA.pdf\n",
      "✅ Saved: sentence_embdedding_files\\66_NTT_DATA.csv\n",
      "Processing: 67_SOFTBANK_GROUP.pdf\n",
      "✅ Saved: sentence_embdedding_files\\67_SOFTBANK_GROUP.csv\n",
      "Processing: 68_FIRST_RETAILING.pdf\n",
      "✅ Saved: sentence_embdedding_files\\68_FIRST_RETAILING.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------- MAIN LOOP --------------------\n",
    "for filename in os.listdir(pdf_folder):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_folder, filename)\n",
    "        print(f\"Processing: {filename}\")\n",
    "        data = []\n",
    "\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                for i, page in enumerate(pdf.pages):\n",
    "                    raw_text = page.extract_text()\n",
    "                    if raw_text:\n",
    "                        sentences = clean_japanese_sentences(raw_text)\n",
    "                        for sentence in sentences:\n",
    "                            data.append({\"page\": i + 1, \"sentence\": sentence})\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"❌ Failed to process {filename} — Error: {error_msg}\")\n",
    "            failed_files.append((filename, error_msg))\n",
    "            continue\n",
    "\n",
    "        if not data:\n",
    "            reason = \"No extractable text\"\n",
    "            print(f\"⚠️ Skipping {filename} — {reason}.\")\n",
    "            skipped_files.append((filename, reason))\n",
    "            continue\n",
    "\n",
    "        # Filter valid sentences using both filters\n",
    "        final_filtered_data = [\n",
    "            row for row in data\n",
    "            if is_valid_sentence(row[\"sentence\"]) and advanced_is_valid_sentence(row[\"sentence\"])\n",
    "        ]\n",
    "\n",
    "        if not final_filtered_data:\n",
    "            reason = \"No valid sentences after filtering\"\n",
    "            print(f\"⚠️ Skipping {filename} — {reason}.\")\n",
    "            skipped_files.append((filename, reason))\n",
    "            continue\n",
    "\n",
    "        # Extract sentence and page info\n",
    "        sentences = [row[\"sentence\"] for row in final_filtered_data]\n",
    "        pages = [row[\"page\"] for row in final_filtered_data]\n",
    "\n",
    "        # Compute embeddings\n",
    "        embeddings = model.encode(sentences).tolist()\n",
    "\n",
    "        # Create DataFrame and save to CSV\n",
    "        df = pd.DataFrame({\n",
    "            \"sentence\": sentences,\n",
    "            \"page\": pages,\n",
    "            \"embedding\": embeddings\n",
    "        })\n",
    "\n",
    "        output_csv_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.csv\")\n",
    "        df.to_csv(output_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"✅ Saved: {output_csv_path}\")\n",
    "        processed_files.append((filename, len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feaf5411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed (61):\n",
      "  - 01_JAPAN_TABACCO.pdf: 422 sentences\n",
      "  - 02_SEVEN&AI_HD.pdf: 219 sentences\n",
      "  - 03_SHINETSU_CHEMISTRY.pdf: 267 sentences\n",
      "  - 04_TAKEDA_PHARMA.pdf: 117 sentences\n",
      "  - 05_CHUGAI_PHARMA.pdf: 189 sentences\n",
      "  - 06_TERUMO.pdf: 290 sentences\n",
      "  - 07_DAIICHI_SANKYO_PHARMA.pdf: 352 sentences\n",
      "  - 08_ORIENTAL_LAND.pdf: 174 sentences\n",
      "  - 09_FUJIFILM_HD.pdf: 260 sentences\n",
      "  - 10_BRIDGESTONE.pdf: 305 sentences\n",
      "  - 11_NIPPONSTEEL.pdf: 351 sentences\n",
      "  - 12_RECRUIT_HD.pdf: 98 sentences\n",
      "  - 14_NIPPON_YUBIN.pdf: 443 sentences\n",
      "  - 15_TOYOTA_INDUSTRIES_CORP.pdf: 218 sentences\n",
      "  - 17_KOMATSU.pdf: 148 sentences\n",
      "  - 18_DAIKIN.pdf: 259 sentences\n",
      "  - 19_HITACHI.pdf: 104 sentences\n",
      "  - 20_MITSAUBISHI_ELECTRIC.pdf: 378 sentences\n",
      "  - 21_NIDEC.pdf: 251 sentences\n",
      "  - 22_FUJITSU.pdf: 263 sentences\n",
      "  - 23_RENESUS.pdf: 90 sentences\n",
      "  - 24_PANASONIC_HD.pdf: 161 sentences\n",
      "  - 25_SONY.pdf: 209 sentences\n",
      "  - 26_ADVANTEST.pdf: 160 sentences\n",
      "  - 28_DENSO.pdf: 484 sentences\n",
      "  - 30_FANUC.pdf: 152 sentences\n",
      "  - 31_KYOCERA.pdf: 110 sentences\n",
      "  - 32_MURATA.pdf: 271 sentences\n",
      "  - 33_MITSUBISHI_HEAVY_INDUSTRIES.pdf: 279 sentences\n",
      "  - 34_YUCHO_BANK.pdf: 189 sentences\n",
      "  - 35_TOYOTA_MOTOR_CORP.pdf: 735 sentences\n",
      "  - 36_HONDA.pdf: 430 sentences\n",
      "  - 37_SUZUKI.pdf: 303 sentences\n",
      "  - 38_HOYA.pdf: 176 sentences\n",
      "  - 39_CANON.pdf: 29 sentences\n",
      "  - 41_ITOCHU.pdf: 358 sentences\n",
      "  - 42_MARUBENI.pdf: 199 sentences\n",
      "  - 43_TOYOTA_TSUSHO.pdf: 347 sentences\n",
      "  - 44_MITSUI_CORP.pdf: 103 sentences\n",
      "  - 45_TOKYO_ELECTRON.pdf: 252 sentences\n",
      "  - 46_SUMITOMO_CORP.pdf: 337 sentences\n",
      "  - 47_MITSUBISHI_CORP.pdf: 118 sentences\n",
      "  - 48_UNICHARM.pdf: 300 sentences\n",
      "  - 49_AEON.pdf: 346 sentences\n",
      "  - 50_MUFG.pdf: 376 sentences\n",
      "  - 52_MIZUHO.pdf: 252 sentences\n",
      "  - 53_ORIX.pdf: 369 sentences\n",
      "  - 54_NOMURA_SEC_HD.pdf: 364 sentences\n",
      "  - 55_SOMPO_HD.pdf: 180 sentences\n",
      "  - 56_MS&AD_INSURE_G.pdf: 275 sentences\n",
      "  - 57_DAIICHI_LIFE.pdf: 573 sentences\n",
      "  - 58_TOKIO_MARINE.pdf: 430 sentences\n",
      "  - 59_MITSU_FUDOSAN.pdf: 231 sentences\n",
      "  - 60_MITSUBISHI_ESTATE.pdf: 110 sentences\n",
      "  - 61_JR_EAST.pdf: 308 sentences\n",
      "  - 63_NTT.pdf: 285 sentences\n",
      "  - 64_KDDI.pdf: 197 sentences\n",
      "  - 65_SOFTBANK.pdf: 216 sentences\n",
      "  - 66_NTT_DATA.pdf: 284 sentences\n",
      "  - 67_SOFTBANK_GROUP.pdf: 483 sentences\n",
      "  - 68_FIRST_RETAILING.pdf: 126 sentences\n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Processed ({len(processed_files)}):\")\n",
    "for fname, count in processed_files:\n",
    "    print(f\"  - {fname}: {count} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fb3840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ Skipped (4):\n",
      "  - 16_SMC_CORP.pdf → No valid sentences after filtering\n",
      "  - 27_KEYENCE.pdf → No valid sentences after filtering\n",
      "  - 40_NINTENDO.pdf → No valid sentences after filtering\n",
      "  - 62_JR_TOKAI.pdf → No extractable text\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\n⚠️ Skipped ({len(skipped_files)}):\")\n",
    "for fname, reason in skipped_files:\n",
    "    print(f\"  - {fname} → {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80f5b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ Failed (0):\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n❌ Failed ({len(failed_files)}):\")\n",
    "for fname, error in failed_files:\n",
    "    print(f\"  - {fname} → Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fc3a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n✅ Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b954893",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e21a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"sentence_embdedding_files\"  # Folder with sentence+embedding CSVs\n",
    "output_folder = \"cosine_similarity_japanese_pdf_file\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01de734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for matching\n",
    "threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efaf3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic vectors (from earlier)\n",
    "topic_vecs = np.vstack(topic_df['embedding_topic'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e81a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Processing: 01_JAPAN_TABACCO.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\01_JAPAN_TABACCO_cosine_matches.csv\n",
      "🔍 Processing: 02_SEVEN&AI_HD.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\02_SEVEN&AI_HD_cosine_matches.csv\n",
      "🔍 Processing: 03_SHINETSU_CHEMISTRY.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\03_SHINETSU_CHEMISTRY_cosine_matches.csv\n",
      "🔍 Processing: 04_TAKEDA_PHARMA.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\04_TAKEDA_PHARMA_cosine_matches.csv\n",
      "🔍 Processing: 05_CHUGAI_PHARMA.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\05_CHUGAI_PHARMA_cosine_matches.csv\n",
      "🔍 Processing: 06_TERUMO.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\06_TERUMO_cosine_matches.csv\n",
      "🔍 Processing: 07_DAIICHI_SANKYO_PHARMA.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\07_DAIICHI_SANKYO_PHARMA_cosine_matches.csv\n",
      "🔍 Processing: 08_ORIENTAL_LAND.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\08_ORIENTAL_LAND_cosine_matches.csv\n",
      "🔍 Processing: 09_FUJIFILM_HD.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\09_FUJIFILM_HD_cosine_matches.csv\n",
      "🔍 Processing: 10_BRIDGESTONE.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\10_BRIDGESTONE_cosine_matches.csv\n",
      "🔍 Processing: 11_NIPPONSTEEL.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\11_NIPPONSTEEL_cosine_matches.csv\n",
      "🔍 Processing: 12_RECRUIT_HD.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\12_RECRUIT_HD_cosine_matches.csv\n",
      "🔍 Processing: 14_NIPPON_YUBIN.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\14_NIPPON_YUBIN_cosine_matches.csv\n",
      "🔍 Processing: 15_TOYOTA_INDUSTRIES_CORP.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\15_TOYOTA_INDUSTRIES_CORP_cosine_matches.csv\n",
      "🔍 Processing: 17_KOMATSU.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\17_KOMATSU_cosine_matches.csv\n",
      "🔍 Processing: 18_DAIKIN.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\18_DAIKIN_cosine_matches.csv\n",
      "🔍 Processing: 19_HITACHI.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\19_HITACHI_cosine_matches.csv\n",
      "🔍 Processing: 20_MITSAUBISHI_ELECTRIC.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\20_MITSAUBISHI_ELECTRIC_cosine_matches.csv\n",
      "🔍 Processing: 21_NIDEC.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\21_NIDEC_cosine_matches.csv\n",
      "🔍 Processing: 22_FUJITSU.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\22_FUJITSU_cosine_matches.csv\n",
      "🔍 Processing: 23_RENESUS.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\23_RENESUS_cosine_matches.csv\n",
      "🔍 Processing: 24_PANASONIC_HD.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\24_PANASONIC_HD_cosine_matches.csv\n",
      "🔍 Processing: 25_SONY.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\25_SONY_cosine_matches.csv\n",
      "🔍 Processing: 26_ADVANTEST.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\26_ADVANTEST_cosine_matches.csv\n",
      "🔍 Processing: 28_DENSO.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\28_DENSO_cosine_matches.csv\n",
      "🔍 Processing: 30_FANUC.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\30_FANUC_cosine_matches.csv\n",
      "🔍 Processing: 31_KYOCERA.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\31_KYOCERA_cosine_matches.csv\n",
      "🔍 Processing: 32_MURATA.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\32_MURATA_cosine_matches.csv\n",
      "🔍 Processing: 33_MITSUBISHI_HEAVY_INDUSTRIES.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\33_MITSUBISHI_HEAVY_INDUSTRIES_cosine_matches.csv\n",
      "🔍 Processing: 34_YUCHO_BANK.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\34_YUCHO_BANK_cosine_matches.csv\n",
      "🔍 Processing: 35_TOYOTA_MOTOR_CORP.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\35_TOYOTA_MOTOR_CORP_cosine_matches.csv\n",
      "🔍 Processing: 36_HONDA.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\36_HONDA_cosine_matches.csv\n",
      "🔍 Processing: 37_SUZUKI.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\37_SUZUKI_cosine_matches.csv\n",
      "🔍 Processing: 38_HOYA.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\38_HOYA_cosine_matches.csv\n",
      "🔍 Processing: 39_CANON.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\39_CANON_cosine_matches.csv\n",
      "🔍 Processing: 41_ITOCHU.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\41_ITOCHU_cosine_matches.csv\n",
      "🔍 Processing: 42_MARUBENI.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\42_MARUBENI_cosine_matches.csv\n",
      "🔍 Processing: 43_TOYOTA_TSUSHO.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\43_TOYOTA_TSUSHO_cosine_matches.csv\n",
      "🔍 Processing: 44_MITSUI_CORP.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\44_MITSUI_CORP_cosine_matches.csv\n",
      "🔍 Processing: 45_TOKYO_ELECTRON.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\45_TOKYO_ELECTRON_cosine_matches.csv\n",
      "🔍 Processing: 46_SUMITOMO_CORP.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\46_SUMITOMO_CORP_cosine_matches.csv\n",
      "🔍 Processing: 47_MITSUBISHI_CORP.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\47_MITSUBISHI_CORP_cosine_matches.csv\n",
      "🔍 Processing: 48_UNICHARM.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\48_UNICHARM_cosine_matches.csv\n",
      "🔍 Processing: 49_AEON.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\49_AEON_cosine_matches.csv\n",
      "🔍 Processing: 50_MUFG.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\50_MUFG_cosine_matches.csv\n",
      "🔍 Processing: 52_MIZUHO.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\52_MIZUHO_cosine_matches.csv\n",
      "🔍 Processing: 53_ORIX.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\53_ORIX_cosine_matches.csv\n",
      "🔍 Processing: 54_NOMURA_SEC_HD.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\54_NOMURA_SEC_HD_cosine_matches.csv\n",
      "🔍 Processing: 55_SOMPO_HD.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\55_SOMPO_HD_cosine_matches.csv\n",
      "🔍 Processing: 56_MS&AD_INSURE_G.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\56_MS&AD_INSURE_G_cosine_matches.csv\n",
      "🔍 Processing: 57_DAIICHI_LIFE.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\57_DAIICHI_LIFE_cosine_matches.csv\n",
      "🔍 Processing: 58_TOKIO_MARINE.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\58_TOKIO_MARINE_cosine_matches.csv\n",
      "🔍 Processing: 59_MITSU_FUDOSAN.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\59_MITSU_FUDOSAN_cosine_matches.csv\n",
      "🔍 Processing: 60_MITSUBISHI_ESTATE.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\60_MITSUBISHI_ESTATE_cosine_matches.csv\n",
      "🔍 Processing: 61_JR_EAST.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\61_JR_EAST_cosine_matches.csv\n",
      "🔍 Processing: 63_NTT.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\63_NTT_cosine_matches.csv\n",
      "🔍 Processing: 64_KDDI.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\64_KDDI_cosine_matches.csv\n",
      "🔍 Processing: 65_SOFTBANK.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\65_SOFTBANK_cosine_matches.csv\n",
      "🔍 Processing: 66_NTT_DATA.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\66_NTT_DATA_cosine_matches.csv\n",
      "🔍 Processing: 67_SOFTBANK_GROUP.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\67_SOFTBANK_GROUP_cosine_matches.csv\n",
      "🔍 Processing: 68_FIRST_RETAILING.csv\n",
      "✅ Saved: cosine_similarity_japanese_pdf_file\\68_FIRST_RETAILING_cosine_matches.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        print(f\"🔍 Processing: {filename}\")\n",
    "\n",
    "        # Load sentence+embedding CSV\n",
    "        df = pd.read_csv(input_path, converters={'embedding': eval})\n",
    "\n",
    "        # Sanity check\n",
    "        required_cols = {'embedding', 'sentence', 'page'}\n",
    "        if df.empty or not required_cols.issubset(df.columns):\n",
    "            print(f\"⚠️ Skipping {filename}: missing one of {required_cols}.\")\n",
    "            continue\n",
    "\n",
    "        # Convert embeddings to array\n",
    "        sentence_vecs = np.vstack(df['embedding'].values)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarity_matrix = cosine_similarity(sentence_vecs, topic_vecs)\n",
    "\n",
    "        # Collect matches\n",
    "        matches = []\n",
    "        for sent_idx, row in enumerate(similarity_matrix):\n",
    "            for topic_idx, score in enumerate(row):\n",
    "                if score >= threshold:\n",
    "                    matches.append({\n",
    "                        'sentence': df.loc[sent_idx, 'sentence'],\n",
    "                        'page': df.loc[sent_idx, 'page'],\n",
    "                        'topic': topic_df.loc[topic_idx, 'topic'],\n",
    "                        'similarity': round(score, 4)\n",
    "                    })\n",
    "\n",
    "        matched_df = pd.DataFrame(matches)\n",
    "\n",
    "        # Save results\n",
    "        output_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_cosine_matches.csv\")\n",
    "        matched_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"✅ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ebfdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6223aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19e84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022e3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e11da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be012bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb631d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f11a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5c86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b54b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8372a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99682b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
